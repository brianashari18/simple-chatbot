{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.441239Z",
     "start_time": "2024-10-18T04:01:49.434081Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.475880Z",
     "start_time": "2024-10-18T04:01:49.465431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming the dialogs.txt is uploaded in your Colab environment\n",
    "file_path = \"./dialogs.txt\"\n",
    "\n",
    "# Load the file\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()"
   ],
   "id": "62df48b8ab5ac3ab",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.497022Z",
     "start_time": "2024-10-18T04:01:49.489146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dialogue_pairs = []\n",
    "for i in range(0, len(lines) - 1, 2):\n",
    "    input_text = lines[i].strip().lower()\n",
    "    response_text = lines[i + 1].strip().lower()\n",
    "    dialogue_pairs.append((input_text, response_text))"
   ],
   "id": "56b495a49a100990",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.513815Z",
     "start_time": "2024-10-18T04:01:49.507304Z"
    }
   },
   "cell_type": "code",
   "source": "dialogues_df = pd.DataFrame(dialogue_pairs, columns=['input', 'response'])",
   "id": "ec9453ea042c96ef",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.584334Z",
     "start_time": "2024-10-18T04:01:49.524887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = Tokenizer()\n",
    "all_text = dialogues_df['input'].tolist() + dialogues_df['response'].tolist()\n",
    "tokenizer.fit_on_texts(all_text)"
   ],
   "id": "e1490c2043cd6e67",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.641116Z",
     "start_time": "2024-10-18T04:01:49.596475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_sequences = tokenizer.texts_to_sequences(dialogues_df['input'])\n",
    "response_sequences = tokenizer.texts_to_sequences(dialogues_df['response'])"
   ],
   "id": "a7c3aab0265025a1",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.657413Z",
     "start_time": "2024-10-18T04:01:49.653244Z"
    }
   },
   "cell_type": "code",
   "source": "vocab_size = len(tokenizer.word_index) + 1",
   "id": "ffcbeddbaa869dea",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.691856Z",
     "start_time": "2024-10-18T04:01:49.674125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Padding the sequences\n",
    "max_sequence_len = max(max([len(seq) for seq in input_sequences]), max([len(seq) for seq in response_sequences]))\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='post')\n",
    "response_sequences = pad_sequences(response_sequences, maxlen=max_sequence_len, padding='post')"
   ],
   "id": "6bb433790e2b0c90",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.755903Z",
     "start_time": "2024-10-18T04:01:49.746298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# Split data into training and validation sets\n",
    "split = int(0.8 * len(input_sequences))\n",
    "X_train, X_val = input_sequences[:split], input_sequences[split:]\n",
    "y_train, y_val = response_sequences[:split], response_sequences[split:]"
   ],
   "id": "7a44515f7f098883",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build Model",
   "id": "7059d0032551a87e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.806535Z",
     "start_time": "2024-10-18T04:01:49.802053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding"
   ],
   "id": "1d9d15270eb80a74",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.818760Z",
     "start_time": "2024-10-18T04:01:49.814557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_dim = 128\n",
    "lstm_units = 256"
   ],
   "id": "a8216e39e011253c",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.884354Z",
     "start_time": "2024-10-18T04:01:49.832210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder_inputs = Input(shape=(max_sequence_len,))\n",
    "encoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_len)(encoder_inputs)\n",
    "encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]"
   ],
   "id": "f321bbe06a656042",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian Anashari\\Desktop\\MyDream\\project\\simple-chatbot\\python_ai_services\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.957639Z",
     "start_time": "2024-10-18T04:01:49.896526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "decoder_inputs = Input(shape=(max_sequence_len,))\n",
    "decoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_len)(decoder_inputs)\n",
    "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ],
   "id": "8f086b1e39bedbe7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian Anashari\\Desktop\\MyDream\\project\\simple-chatbot\\python_ai_services\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.973555Z",
     "start_time": "2024-10-18T04:01:49.967887Z"
    }
   },
   "cell_type": "code",
   "source": "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)",
   "id": "648104fe15982252",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:49.994512Z",
     "start_time": "2024-10-18T04:01:49.986981Z"
    }
   },
   "cell_type": "code",
   "source": "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')",
   "id": "7aa18a760d4cca53",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:01:50.056165Z",
     "start_time": "2024-10-18T04:01:50.037648Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()\n",
   "id": "c7ddb5daf323fcb6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_4\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_9       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_8         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │    \u001B[38;5;34m322,560\u001B[0m │ input_layer_8[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_9         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │    \u001B[38;5;34m322,560\u001B[0m │ input_layer_9[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_8 (\u001B[38;5;33mLSTM\u001B[0m)       │ [(\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m),     │    \u001B[38;5;34m394,240\u001B[0m │ embedding_8[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m),      │            │                   │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_9 (\u001B[38;5;33mLSTM\u001B[0m)       │ [(\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m256\u001B[0m), │    \u001B[38;5;34m394,240\u001B[0m │ embedding_9[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m… │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m),      │            │ lstm_8[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m1\u001B[0m],     │\n",
       "│                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)]      │            │ lstm_8[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m2\u001B[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m2520\u001B[0m)  │    \u001B[38;5;34m647,640\u001B[0m │ lstm_9[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">322,560</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_9         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">322,560</span> │ input_layer_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2520</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">647,640</span> │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m2,081,240\u001B[0m (7.94 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,081,240</span> (7.94 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m2,081,240\u001B[0m (7.94 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,081,240</span> (7.94 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train the Model",
   "id": "69939848695153c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T04:02:05.210513Z",
     "start_time": "2024-10-18T04:02:05.098955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train, y_train[:, :-1]], \n",
    "    np.expand_dims(y_train[:, 1:], -1),  # Ensure y_train is shaped correctly\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=([X_val, y_val[:, :-1]], np.expand_dims(y_val[:, 1:], -1))\n",
    ")\n"
   ],
   "id": "c9d7e9f0cf97c658",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 1 of layer \"functional_4\" is incompatible with the layer: expected shape=(None, 32), found shape=(None, 31)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[86], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Ensure y_train is shaped correctly\u001B[39;49;00m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand_dims\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_val\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\MyDream\\project\\simple-chatbot\\python_ai_services\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\Desktop\\MyDream\\project\\simple-chatbot\\python_ai_services\\.venv\\Lib\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001B[0m, in \u001B[0;36massert_input_compatibility\u001B[1;34m(input_spec, inputs, layer_name)\u001B[0m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec_dim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m dim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    244\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m spec_dim \u001B[38;5;241m!=\u001B[39m dim:\n\u001B[1;32m--> 245\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    246\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of layer \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    247\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mincompatible with the layer: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    248\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpected shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mspec\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    249\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    250\u001B[0m         )\n",
      "\u001B[1;31mValueError\u001B[0m: Input 1 of layer \"functional_4\" is incompatible with the layer: expected shape=(None, 32), found shape=(None, 31)"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to generate responses\n",
    "def generate_response(input_text):\n",
    "    # Preprocess the input text\n",
    "    input_sequence = tokenizer.texts_to_sequences([input_text.lower()])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=max_sequence_len, padding='post')\n",
    "\n",
    "    # Predict the response sequence\n",
    "    states_value = encoder_model.predict(input_sequence)\n",
    "    target_sequence = np.zeros((1, 1))\n",
    "    target_sequence[0, 0] = tokenizer.word_index['start_token']\n",
    "\n",
    "    stop_condition = False\n",
    "    generated_sequence = []\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_sequence] + states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = tokenizer.index_word[sampled_token_index]\n",
    "        generated_sequence.append(sampled_word)\n",
    "\n",
    "        if sampled_word == 'end_token' or len(generated_sequence) > max_sequence_len:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_sequence = np.zeros((1, 1))\n",
    "        target_sequence[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(generated_sequence)\n",
    "\n",
    "# Example of generating a response\n",
    "user_input = \"how's it going?\"\n",
    "print(\"Bot:\", generate_response(user_input))"
   ],
   "id": "c1c00d19bcc5427e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the model\n",
    "model.save(\"chatbot_model.h5\")"
   ],
   "id": "50f4c8a856bd2f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model(\"chatbot_model.h5\")"
   ],
   "id": "779f88e3509f4e1a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
